# -*- coding: utf-8 -*-
"""바이그램시각화최종.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/155BqLz6zB5JNH-sYHm8g8NKBbAndnaPG
"""

from google.colab import drive
import pandas as pd

# Google Drive 마운트
drive.mount('/content/drive')

!pip install gensim

from wordcloud import WordCloud
import matplotlib.pyplot as plt
import pandas as pd
from pandas import DataFrame
import os
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
import pandas as pd
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from collections import Counter
import string

from nltk import ngrams

nltk.download('punkt')
nltk.download('stopwords')

file_paths = [
    '/content/drive/My Drive/BDPgo/2013to14.csv',
    '/content/drive/My Drive/BDPgo/2015.csv',
    '/content/drive/My Drive/BDPgo/2016.csv',
    '/content/drive/My Drive/BDPgo/2017.csv',
    '/content/drive/My Drive/BDPgo/2018.csv',
    '/content/drive/My Drive/BDPgo/2019.csv',
    '/content/drive/My Drive/BDPgo/2020.csv',
    '/content/drive/My Drive/BDPgo/2021to22.csv',
    '/content/drive/My Drive/BDPgo/2023.csv'
]

dfs = []  # 각 CSV 파일의 데이터를 저장할 리스트
for file_path in file_paths:
    df = pd.read_csv(file_path)
    dfs.append(df)

# 모든 데이터프레임을 하나로 합칩니다.
df_all = pd.concat(dfs, ignore_index=True)
df = df_all

# Drop 'Authors' and 'Subjects' columns
df = df.drop(['Authors', 'Subjects'], axis=1)

#불용어 리스트
stop_words = set(stopwords.words('english'))  # 언어에 따라 변경 가능
# 문장부호 문자열
punctuation = set(string.punctuation)

# 불용어 및 문장부호 제거 함수
def preprocess_text(text):
    words = word_tokenize(text)
    filtered_words = [word.lower() for word in words if word.lower() not in stop_words and word not in punctuation]
    return ' '.join(filtered_words)

df['Title'] = df['Title'].str.replace('Title: ', '')
df['Title'] = df['Title'].str.replace('title ', '')
df['Title'] = df['Title'].str.lower()
df['Abstract'] = df['Abstract'].str.lower()
# 칼럼 에 불용어 및 문장부호 제거 적용
df['Abstract'] = df['Abstract'].apply(preprocess_text)
df['Title'] = df['Title'].apply(preprocess_text)

def generate_bigrams(text):
  words = word_tokenize(text)
  filtered_words = [word.lower() for word in words if word.lower() not in stop_words and word not in punctuation]
  bigrams = ['_'.join(map(str, gram)) for gram in nltk.ngrams(filtered_words, 2)]
  return ' '.join(bigrams)

# 칼럼에 바이그램 생성 적용
df['Abstract_bigrams'] = df['Abstract'].apply(generate_bigrams)
df['Title_bigrams'] = df['Title'].apply(generate_bigrams)

df[df['Year'] == 2013]

# 각 년도에 대한 랭킹을 저장할 딕셔너리
ranking_per_year = {}

for year in range(2013, 2024):  # 2013년부터 2023년까지
    text = ' '.join(df.loc[df['Year'] == year, 'Abstract_bigrams'])

    word_counts = Counter(text.split())

    ranking = word_counts.most_common()

    # 각 년도의 랭킹을 딕셔너리에 저장
    ranking_per_year[year] = ranking

top_20_ranking_per_year = {}

for year in range(2013, 2024):
    # 각 연도별 전체 랭킹에서 상위 20개만 선택
    top_20_ranking = ranking_per_year[year][:20]

    top_20_ranking_per_year[year] = top_20_ranking

# 사용자에게 연도를 입력받음
input_year = int(input("조회하려는 연도를 입력하세요 (2013~2023): "))

df_ranking = pd.DataFrame(top_20_ranking_per_year[input_year], columns=["키워드", "빈도수"])

# 빈도수가 높은 순으로 정렬하여 키워드를 리스트로 저장
sorted_list = df_ranking.sort_values(by="빈도수", ascending=False)["키워드"].tolist()

# 결과 출력
var_name = f"sorted_list{input_year}"
globals()[var_name] = sorted_list  # 동적으로 변수를 생성하고 할당

#위의 코드를 실행해서 연도를 하나씩 다 입력해주면, sorted_list2013 부터 sorted_list2023까지 생성됌.

# 사용자에게 연도를 입력받음
year = int(input("조회하려는 연도를 입력하세요 (2013~2023): "))

# 입력받은 연도의 상위 20개 단어 랭킹을 딕셔너리로 변환
word_freq = dict(top_20_ranking_per_year[year])

# 워드 클라우드 생성
wc = WordCloud(width=500, height=500, max_words=200, background_color='white').generate_from_frequencies(word_freq)

# 워드 클라우드 출력
plt.figure(figsize=(10, 5))
plt.imshow(wc, interpolation='bilinear')
plt.axis('off')
plt.show()

#폰트
plt.rcParams['font.family'] = 'Arial'

# 'Year' 열을 기준으로 데이터 그룹화 및 각 그룹의 수 계산
yearly_counts = df['Year'].value_counts().sort_index()

# 선그래프 출력
plt.figure(figsize=(10, 6))
plt.plot(yearly_counts.index, yearly_counts.values, marker='o')
plt.title('Yearly Paper Count')   #연도별 논문수
plt.xlabel('Year')                  # 연도
plt.ylabel('Paper Count')           #논문수
plt.xticks(range(2014, 2024))  # x축 눈금을 1년 단위로 설정
plt.grid()
plt.show()

#이제 df2013과 sorted_list2013을 비교해야함.
#df2013의 Abstract_bigrams컬럼안에 들어있는 내용들 중, 얼마나 많이 sorted_list2013에 있는 단어들을 포함하고 싶은지 count를 하여 count컬럼을 추가하고 count를 기준으로 내림차순으로 출력.
#그리고  'total_count'순으로 정렬해서 탑3개만 출력.

df2013 = df[df['Year'] == 2013]
df2014 = df[df['Year'] == 2014]
df2015 = df[df['Year'] == 2015]
df2016 = df[df['Year'] == 2016]
df2017 = df[df['Year'] == 2017]
df2018 = df[df['Year'] == 2018]
df2019 = df[df['Year'] == 2019]
df2020 = df[df['Year'] == 2020]
df2021 = df[df['Year'] == 2021]
df2022 = df[df['Year'] == 2022]
df2023 = df[df['Year'] == 2023]

#정리해서 말하면, 2013~2023년 각 연도별로  탑20개의 키워드를 바탕으로 하여,
#각 연도마다 각 상위 20개의 키워드가 가장많이 등장하는 논문의 Title을 뽑고,
#키워드가 몇번이나 등장하는지 count 칼럼을 추가하여 count를 기준으로 내림차순 정렬해서  출력.
#출력형식 : year,month,title,total_count
# 의미 :  결국 이렇게 유저가 해당 연도에 어떤 논문이 인기있었는지 볼수있다. 인기 지표 : 키워드

# 'Abstract_bigrams' 컬럼 안에 sorted_list2013에 있는 단어들이 몇 번 나타나는지 카운트하여 'count' 컬럼 추가
for keyword in sorted_list2013:
    df2013[keyword + '_count'] = df2013['Abstract_bigrams'].apply(lambda x: x.count(keyword))

# sorted_list2013에 있는 단어들의 카운트를 모두 더한 값을 'total_count' 컬럼으로 추가
df2013['total_count'] = df2013[[keyword + '_count' for keyword in sorted_list2013]].sum(axis=1)

# 원하는 컬럼만 선택
df2013_sorted = df2013[['Year',	'Month',	'Title','total_count']]
# 'total_count'를 기준으로 내림차순 정렬
df2013_sorted = df2013_sorted.sort_values(by='total_count', ascending=False)
df2013_sorted.head(3)

# 'Abstract_bigrams' 컬럼 안에 sorted_list2013에 있는 단어들이 몇 번 나타나는지 카운트하여 'count' 컬럼 추가
for keyword in sorted_list2014:
    df2014[keyword + '_count'] = df2014['Abstract_bigrams'].apply(lambda x: x.count(keyword))

# sorted_list2013에 있는 단어들의 카운트를 모두 더한 값을 'total_count' 컬럼으로 추가
df2014['total_count'] = df2014[[keyword + '_count' for keyword in sorted_list2014]].sum(axis=1)

# 원하는 컬럼만 선택
df2014_sorted = df2014[['Year',	'Month',	'Title','total_count']]
# 'total_count'를 기준으로 내림차순 정렬
df2014_sorted = df2014_sorted.sort_values(by='total_count', ascending=False)
df2014_sorted.head(3)



# 'Abstract_bigrams' 컬럼 안에 sorted_list2013에 있는 단어들이 몇 번 나타나는지 카운트하여 'count' 컬럼 추가
for keyword in sorted_list2015:
    df2015[keyword + '_count'] = df2015['Abstract_bigrams'].apply(lambda x: x.count(keyword))

# sorted_list2013에 있는 단어들의 카운트를 모두 더한 값을 'total_count' 컬럼으로 추가
df2015['total_count'] = df2015[[keyword + '_count' for keyword in sorted_list2015]].sum(axis=1)

# 원하는 컬럼만 선택
df2015_sorted = df2015[['Year',	'Month',	'Title','total_count']]
# 'total_count'를 기준으로 내림차순 정렬
df2015_sorted = df2015_sorted.sort_values(by='total_count', ascending=False)
df2015_sorted.head(3)

# 'Abstract_bigrams' 컬럼 안에 sorted_list2013에 있는 단어들이 몇 번 나타나는지 카운트하여 'count' 컬럼 추가
for keyword in sorted_list2016:
    df2016[keyword + '_count'] = df2016['Abstract_bigrams'].apply(lambda x: x.count(keyword))

# sorted_list2013에 있는 단어들의 카운트를 모두 더한 값을 'total_count' 컬럼으로 추가
df2016['total_count'] = df2016[[keyword + '_count' for keyword in sorted_list2016]].sum(axis=1)

# 원하는 컬럼만 선택
df2016_sorted = df2016[['Year',	'Month',	'Title','total_count']]
# 'total_count'를 기준으로 내림차순 정렬
df2016_sorted = df2016_sorted.sort_values(by='total_count', ascending=False)
df2016_sorted.head(3)

# 'Abstract_bigrams' 컬럼 안에 sorted_list2013에 있는 단어들이 몇 번 나타나는지 카운트하여 'count' 컬럼 추가
for keyword in sorted_list2017:
    df2017[keyword + '_count'] = df2017['Abstract_bigrams'].apply(lambda x: x.count(keyword))

# sorted_list2013에 있는 단어들의 카운트를 모두 더한 값을 'total_count' 컬럼으로 추가
df2017['total_count'] = df2017[[keyword + '_count' for keyword in sorted_list2017]].sum(axis=1)

# 원하는 컬럼만 선택
df2017_sorted = df2017[['Year',	'Month',	'Title','total_count']]
# 'total_count'를 기준으로 내림차순 정렬
df2017_sorted = df2017_sorted.sort_values(by='total_count', ascending=False)
df2017_sorted.head(3)

# 'Abstract_bigrams' 컬럼 안에 sorted_list2013에 있는 단어들이 몇 번 나타나는지 카운트하여 'count' 컬럼 추가
for keyword in sorted_list2018:
    df2018[keyword + '_count'] = df2018['Abstract_bigrams'].apply(lambda x: x.count(keyword))

# sorted_list2013에 있는 단어들의 카운트를 모두 더한 값을 'total_count' 컬럼으로 추가
df2018['total_count'] = df2018[[keyword + '_count' for keyword in sorted_list2018]].sum(axis=1)

# 원하는 컬럼만 선택
df2018_sorted = df2018[['Year',	'Month',	'Title','total_count']]
# 'total_count'를 기준으로 내림차순 정렬
df2018_sorted = df2018_sorted.sort_values(by='total_count', ascending=False)
df2018_sorted.head(3)

# 'Abstract_bigrams' 컬럼 안에 sorted_list2013에 있는 단어들이 몇 번 나타나는지 카운트하여 'count' 컬럼 추가
for keyword in sorted_list2019:
    df2019[keyword + '_count'] = df2019['Abstract_bigrams'].apply(lambda x: x.count(keyword))

# sorted_list2013에 있는 단어들의 카운트를 모두 더한 값을 'total_count' 컬럼으로 추가
df2019['total_count'] = df2019[[keyword + '_count' for keyword in sorted_list2019]].sum(axis=1)

# 원하는 컬럼만 선택
df2019_sorted = df2019[['Year',	'Month',	'Title','total_count']]
# 'total_count'를 기준으로 내림차순 정렬
df2019_sorted = df2019_sorted.sort_values(by='total_count', ascending=False)
df2019_sorted.head(3)

# 'Abstract_bigrams' 컬럼 안에 sorted_list2013에 있는 단어들이 몇 번 나타나는지 카운트하여 'count' 컬럼 추가
for keyword in sorted_list2020:
    df2020[keyword + '_count'] = df2020['Abstract_bigrams'].apply(lambda x: x.count(keyword))

# sorted_list2013에 있는 단어들의 카운트를 모두 더한 값을 'total_count' 컬럼으로 추가
df2020['total_count'] = df2020[[keyword + '_count' for keyword in sorted_list2020]].sum(axis=1)

# 원하는 컬럼만 선택
df2020_sorted = df2020[['Year',	'Month',	'Title','total_count']]
# 'total_count'를 기준으로 내림차순 정렬
df2020_sorted = df2020_sorted.sort_values(by='total_count', ascending=False)
df2020_sorted.head(3)

# 'Abstract_bigrams' 컬럼 안에 sorted_list2013에 있는 단어들이 몇 번 나타나는지 카운트하여 'count' 컬럼 추가
for keyword in sorted_list2021:
    df2021[keyword + '_count'] = df2021['Abstract_bigrams'].apply(lambda x: x.count(keyword))

# sorted_list2013에 있는 단어들의 카운트를 모두 더한 값을 'total_count' 컬럼으로 추가
df2021['total_count'] = df2021[[keyword + '_count' for keyword in sorted_list2021]].sum(axis=1)

# 원하는 컬럼만 선택
df2021_sorted = df2021[['Year',	'Month',	'Title','total_count']]
# 'total_count'를 기준으로 내림차순 정렬
df2021_sorted = df2021_sorted.sort_values(by='total_count', ascending=False)
df2021_sorted.head(3)

# 'Abstract_bigrams' 컬럼 안에 sorted_list2013에 있는 단어들이 몇 번 나타나는지 카운트하여 'count' 컬럼 추가
for keyword in sorted_list2022:
    df2022[keyword + '_count'] = df2022['Abstract_bigrams'].apply(lambda x: x.count(keyword))

# sorted_list2013에 있는 단어들의 카운트를 모두 더한 값을 'total_count' 컬럼으로 추가
df2022['total_count'] = df2022[[keyword + '_count' for keyword in sorted_list2022]].sum(axis=1)

# 원하는 컬럼만 선택
df2022_sorted = df2022[['Year',	'Month',	'Title','total_count']]
# 'total_count'를 기준으로 내림차순 정렬
df2022_sorted = df2022_sorted.sort_values(by='total_count', ascending=False)
df2022_sorted.head(3)

# 'Abstract_bigrams' 컬럼 안에 sorted_list2013에 있는 단어들이 몇 번 나타나는지 카운트하여 'count' 컬럼 추가
for keyword in sorted_list2023:
    df2023[keyword + '_count'] = df2023['Abstract_bigrams'].apply(lambda x: x.count(keyword))

# sorted_list2013에 있는 단어들의 카운트를 모두 더한 값을 'total_count' 컬럼으로 추가
df2023['total_count'] = df2023[[keyword + '_count' for keyword in sorted_list2023]].sum(axis=1)

# 원하는 컬럼만 선택
df2023_sorted = df2023[['Year',	'Month',	'Title','total_count']]
# 'total_count'를 기준으로 내림차순 정렬
df2023_sorted = df2023_sorted.sort_values(by='total_count', ascending=False)
df2023_sorted.head(3)

