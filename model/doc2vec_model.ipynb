{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YtDgLLCmSG5z"},"outputs":[],"source":["class TaggedDocumentIterator(object):\n","\n","  def __init__(self, doc_list, labels_list):\n","      self.labels_list = labels_list\n","      self.doc_list = doc_list\n","\n","  def __iter__(self):\n","      for idx, doc in enumerate(self.doc_list):\n","        for idy in enumerate(doc):\n","          yield TaggedDocument(words=idy[1].split(), tags=[str(self.labels_list[idx]) + '.' + str(doc.index(idy[1]))])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6IkNPc-CSKL7"},"outputs":[],"source":["docLabels = list(range(len(paper_df)))\n","doc_list = list(paper_df)\n","tag_doc_iter = TaggedDocumentIterator(doc_list, docLabels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lxcWar6dCChv"},"outputs":[],"source":["from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","from nltk.tokenize import word_tokenize\n","import nltk\n","nltk.download('punkt')\n","\n","# Doc2Vec model training\n","def train_doc2vec(papers, tagged_data):\n","    #tagged_data = [TaggedDocument(words=word_tokenize(paper.lower()), tags=[str(i)]) for i, paper in enumerate(papers)]\n","\n","    model = Doc2Vec(vector_size=300, window=8, min_count=1, workers=8, epochs=100, alpha=0.025, min_alpha=0.025)\n","    #vector_size=300, alpha=0.025, min_alpha=0.025, workers=8, window=8\n","    #vector_size=100, window=4, min_count=1, workers=8, epochs=100\n","\n","    model.build_vocab(tagged_data)\n","\n","    model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n","\n","    return model, tagged_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KR2V25N8CEYm"},"outputs":[],"source":["def modst_similar(model, new_abstract):\n","  # vector extraction about new abstract\n","  new_vector = model.infer_vector(word_tokenize(new_abstract.lower()))\n","\n","  # 각 논문과의 유사도 계산\n","  similarities = model.dv.cosine_similarities(new_vector, model.wv.vectors)\n","\n","  # 유사도에 따라 정렬\n","  sorted_similarities = sorted(enumerate(similarities), key=lambda x: x[1], reverse=True)\n","\n","  # 가장 유사한 논문 출력\n","  top_similar_paper_idx, top_similarity = sorted_similarities[0]\n","  top_similar_paper = paper_df.iloc[top_similar_paper_idx]\n","  print(f\"Most similar paper:\")\n","  print(f\"Title: {top_similar_paper['Title']}\")\n","  print(f\"Abstract: {top_similar_paper['Abstract']}\")"]},{"cell_type":"markdown","metadata":{"id":"jgnKLio4CGaT"},"source":["\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lVcSkx98CHqa"},"outputs":[],"source":["model, tagged_data = train_doc2vec(paper_df, tag_doc_iter)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WoRt1eroCOWS"},"outputs":[],"source":["# new abstract\n","\n","new_abstract = 'Alzheimer’s disease (AD) is the most common late‐onset neurodegenerative disorder. \\\n","Identifying individuals at increased risk of developing AD is important for early intervention. \\\n","Using data from the Alzheimer Disease Genetics Consortium, we constructed polygenic risk scores (PRSs) for AD and age‐ at‐onset (AAO) of AD for the UK Biobank participants. \\\n","We then built machine learning (ML) models for predicting development of AD, and explored feature importance among PRSs, conventional risk factors, \\\n","and ICD‐10 codes from electronic health records, a total of > 11,000 features using the UK Biobank dataset. \\\n","We used eXtreme Gradient Boosting (XGBoost) and SHapley Additive exPlanations (SHAP), which provided superior ML performance as well as aided ML model explanation. \\\n","For participants age 40 and older, the area under the curve for AD was 0.88. For subjects of age 65 and older (late‐onset AD), PRSs were the most important predictors. \\\n","This is the first observation that PRSs constructed from the AD risk and AAO play more important roles than age in predicting AD. \\\n","The ML model also identified important predictors from EHR, including urinary tract infection, syncope and collapse, chest pain, disorientation and hypercholesterolemia, for developing AD. \\\n","Our ML model improved the accuracy of AD risk prediction by efficiently exploring numerous predictors and identified novel feature patterns.'\n","\n","\"\"\"\n","new_abstract = \"NFTrig is a web-based application created for use as an educational tool to teach trigonometry and block chain technology. \\\n","Creation of the application includes front and back end development as well as integration with other outside sources including MetaMask and OpenSea. \\\n","The primary development languages include HTML, CSS (Bootstrap 5), and JavaScript as well as Solidity for smart contract creation. \\\n","The application itself is hosted on Moralis utilizing their Web3 API. \\\n","This technical report describes how the application was created, what the application requires, and smart contract design with security considerations in mind. \\\n","The NFTrig application has underwent significant testing and validation prior to and after deployment. \\\n","Future suggestions and recommendations for further development, maintenance, and use in other fields for education are also described.\"\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LPSg2q-OCQFT"},"outputs":[],"source":["most_paper = modst_similar(model, new_abstract)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SHWV0XaDCRqZ"},"outputs":[],"source":["def similarity_paper_extraction(new_abstract, model):\n","  # vector extraction about new abstract\n","  new_vector = model.infer_vector(word_tokenize(new_abstract.lower()))\n","\n","  # 각 논문과의 유사도 계산\n","  similarities = model.dv.cosine_similarities(new_vector, model.wv.vectors)\n","\n","  # 유사도에 따라 정렬\n","  sorted_similarities = sorted(enumerate(similarities), key=lambda x: x[1], reverse=True)\n","\n","  similar_papers = []\n","  for idx, similarity in sorted_similarities:\n","      top_similar_paper = paper_df.iloc[idx]\n","      similar_papers.append(top_similar_paper)\n","      #print(f\"Similarity: {similarity:.4f}\")\n","      #print(f\"Title: {top_similar_paper['Title']}\")\n","      #print(f\"Abstract: {top_similar_paper['Abstract']}\")\n","      #print()\n","\n","  similar_paper_df = pd.DataFrame(similar_papers)\n","  #similar_papers_df.to_csv('similar_papers.csv', index=False)\n","  similar_paper_df\n","\n","  return sorted_similarities, similar_paper_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6eAZ_aihCTbv"},"outputs":[],"source":["sorted_similarities, similar_paper_df = similarity_paper_extraction(new_abstract, model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fnkgMSumCU5s"},"outputs":[],"source":["similar_paper_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DmWYi6IACWal"},"outputs":[],"source":["sorted_similarities"]},{"cell_type":"code","source":["# test 2023-11-23"],"metadata":{"id":"o4Pn_eDueJVU","executionInfo":{"status":"ok","timestamp":1700747899504,"user_tz":-540,"elapsed":10,"user":{"displayName":"Jiyeong Shin","userId":"02884974254541076563"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"FhFIO7YLeMIs"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}