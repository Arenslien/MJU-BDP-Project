# -*- coding: utf-8 -*-
"""Word2Vec.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M0kSmRTH9MWhkOBbeeMt2fF2DTmeBFOw
"""

import pandas as pd
import numpy as np
from gensim.models import Word2Vec
from sklearn.metrics.pairwise import cosine_similarity
import string
import nltk
import nltk
nltk.download('punkt')
from google.colab import drive
drive.mount('/content/drive')

file_path = '/content/drive/My Drive/BDPgo/MJU-BDP-Project/model/paper_CS_2021.csv'
paper_df = pd.read_csv(file_path, encoding='utf-8')

paper_df.head(10)

from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.corpus import stopwords
import string
from tqdm import tqdm

# 텍스트 전처리 함수 정의
def preprocess_text(text):
    tokens = word_tokenize(text)  # 단어 토큰화
    tokens = [token for token in tokens if token not in string.punctuation]  # 구두점 제거
    return tokens

# 논문 데이터 전처리
corpus = [preprocess_text(abstract) for abstract in tqdm(paper_df['Abstract'])]

# Word2Vec 모델 학습
model = Word2Vec(sentences=corpus, vector_size=100, window=5, min_count=5, workers=4, sg=0)

# 사용자로부터 입력 받기
#user_input = input("단어 유사도를 확인할 문장을 입력하세요: ")

# 입력 문장을 전처리하고 모델에서 어휘와의 유사도 확인
input_tokens = preprocess_text(user_input)
similar_words = model.wv.most_similar(input_tokens)

# 결과 출력
print(f"입력한 문장: {user_input}")
print("어휘에 있는 단어들과의 유사도:")
for word, similarity in similar_words:
    print(f"({word}, {similarity:.4f})")